# Topic: The Perceptron and Backpropagation.

- Weights and Biases: How parameters are adjusted.

- Activation Functions: ReLU (the standard), Sigmoid (output), Softmax (multi-class).

- Gradient Descent: Minimizing the Loss Function.